<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Using ResNet101 for Concrete Crack Detection</title>
  <link rel="stylesheet" href="../styles.css">
  <link rel="stylesheet" href="../css/all.min.css">
  <link rel="icon" type="image/x-icon" href="../MB.png">
</head>
<body>
  <!-- Navigation -->
  <nav>
    <div class="container">
      <a href="../index.html" class="logo">Milad Badeleh</a>
      <button class="menu-toggle" aria-label="Toggle navigation">
        <i class="fas fa-bars"></i>
      </button>
      <ul class="nav-links">
        <li><a href="#about" data-translate="about">About</a></li>
        <li><a href="#research" data-translate="research">Research</a></li>
        <!-- <li><a href="#publications" data-translate="publications">Publications</a></li> -->
        <li><a href="#cv" data-translate="cv">CV</a></li>
        <li><a href="#contact" data-translate="contact">Contact</a></li>
      </ul>
      <!-- Language Selector -->
      <div class="language-selector-wrapper">
        <select id="language-selector">
          <option value="en">English</option>
          <option value="de">Deutsch</option>
          <option value="ru">Русский</option>
          <option value="zh">中文</option>
          <option value="sp">español</option>
          <option value="fr">Français</option>
          <!-- <option value="ar">العربية</option> -->
          <option value="po">Português</option>
          <option value="it">Italiano</option>
          <option value="nl">ِDutch</option>
          <option value="hi">हिंदी</option>
          <option value="ba">বাংলা</option>
        </select>
        <i class="fas fa-globe"></i>
      </div>
      
    </div>
  </nav>

  <!-- Research Content -->
  <section class="research-detail">
    <div class="container">

<h1>DenseNet Model: A Deep Learning Approach for Image Classification</h1>

<div class="section">
    <h2>Introduction</h2>
    <p>
        The DenseNet (Densely Connected Convolutional Network) is a state-of-the-art deep learning architecture designed for image classification tasks. Unlike traditional convolutional neural networks (CNNs), DenseNet connects each layer to every other layer in a feed-forward fashion, enabling feature reuse and improving gradient flow. This architecture is particularly effective for tasks where high accuracy is required, such as medical imaging, object detection, and general image classification.
    </p>
</div>

<div class="section">
    <h2>Key Features of DenseNet</h2>
    <p>
        DenseNet introduces several key innovations:
    </p>
    <ul>
        <li><strong>Dense Connectivity:</strong> Each layer in DenseNet receives input from all preceding layers and passes its feature maps to all subsequent layers. This promotes feature reuse and reduces the number of parameters.</li>
        <li><strong>Feature Concatenation:</strong> Instead of summing feature maps (as in ResNet), DenseNet concatenates them, which helps preserve information and improves model performance.</li>
        <li><strong>Bottleneck Layers:</strong> To reduce computational complexity, DenseNet uses 1x1 convolutional layers (bottleneck layers) before applying 3x3 convolutions.</li>
        <li><strong>Transition Layers:</strong> These layers are used to control the growth of feature maps by reducing their dimensionality, ensuring efficient computation.</li>
    </ul>
</div>

<div class="section">
    <h2>Model Architecture</h2>
    <p>
        The DenseNet model used in this implementation is <strong>DenseNet121</strong>, which consists of 121 layers. The architecture is divided into dense blocks and transition layers:
    </p>
    <ul>
        <li><strong>Dense Blocks:</strong> Each dense block contains multiple layers where each layer is connected to every other layer within the block. This encourages feature reuse and improves gradient flow.</li>
        <li><strong>Transition Layers:</strong> These layers are placed between dense blocks to reduce the dimensionality of feature maps using 1x1 convolutions and average pooling.</li>
    </ul>
    <p>
        The final layer of the model is a fully connected (FC) layer, which is modified to match the number of classes in the dataset.
    </p>
</div>

<div class="section">
    <h2>Training Process</h2>
    <p>
        The model is trained using the following steps:
    </p>
    <ol>
        <li><strong>Data Preparation:</strong> The dataset is preprocessed using transformations such as resizing, normalization, and conversion to tensors. The dataset is split into training, validation, and test sets.</li>
        <li><strong>Model Initialization:</strong> The DenseNet121 model is initialized with pre-trained weights from ImageNet. The final fully connected layer is modified to match the number of classes in the dataset.</li>
        <li><strong>Loss Function:</strong> The CrossEntropyLoss function is used to measure the difference between the predicted and actual labels.</li>
        <li><strong>Optimizer:</strong> The Adam optimizer is used to update the model's parameters during training.</li>
        <li><strong>Training Loop:</strong> The model is trained for a specified number of epochs. During each epoch, the model is evaluated on the validation set to monitor performance.</li>
        <li><strong>Model Saving:</strong> After training, the model's weights are saved for future use.</li>
        <li><strong>Testing:</strong> The model is evaluated on the test set to measure its generalization performance.</li>
    </ol>
</div>

<div class="section">
    <h2>Advantages of DenseNet</h2>
    <p>
        DenseNet offers several advantages over traditional CNNs:
    </p>
    <ul>
        <li><strong>Feature Reuse:</strong> By connecting each layer to every other layer, DenseNet encourages the reuse of features, leading to more efficient learning.</li>
        <li><strong>Reduced Vanishing Gradient:</strong> The dense connectivity improves gradient flow, making it easier to train very deep networks.</li>
        <li><strong>Parameter Efficiency:</strong> DenseNet requires fewer parameters compared to other architectures like ResNet, making it more memory-efficient.</li>
        <li><strong>High Accuracy:</strong> DenseNet achieves state-of-the-art performance on various image classification benchmarks.</li>
    </ul>
</div>

<div class="section">
    <h2>Applications</h2>
    <p>
        DenseNet is widely used in various applications, including:
    </p>
    <ul>
        <li><strong>Medical Imaging:</strong> DenseNet is used for tasks such as tumor detection, organ segmentation, and disease classification.</li>
        <li><strong>Object Detection:</strong> The architecture is used in object detection frameworks like Faster R-CNN and YOLO.</li>
        <li><strong>General Image Classification:</strong> DenseNet is used for tasks such as classifying images into categories like animals, vehicles, and more.</li>
    </ul>
</div>
<h2>Results</h2>
<p>The DenseNet121 model was trained for <strong>10 epochs</strong> on the custom dataset, achieving excellent performance across training, validation, and test sets. Below are the detailed results:</p>

<h3>Training Performance</h3>
<ul>
  <li><strong>Training Accuracy</strong>: The model achieved a training accuracy of <strong>99.77%</strong> by the 10th epoch, with a training loss of <strong>0.0089</strong>.</li>
  <li><strong>Validation Accuracy</strong>: The validation accuracy reached <strong>99.81%</strong> by the 10th epoch, with a validation loss of <strong>0.0063</strong>.</li>
  <li><strong>Test Accuracy</strong>: The model achieved a test accuracy of <strong>99.86%</strong>, with a test loss of <strong>0.0038</strong>.</li>
</ul>

<h3>Performance Over Epochs</h3>
<p>The model showed consistent improvement over the training epochs:</p>
<ul>
  <li><strong>Epoch 1</strong>: Training Accuracy = 99.05%, Validation Accuracy = 99.71%</li>
  <li><strong>Epoch 2</strong>: Training Accuracy = 99.59%, Validation Accuracy = 99.78%</li>
  <li><strong>Epoch 3</strong>: Training Accuracy = 99.69%, Validation Accuracy = 99.86%</li>
  <li><strong>Epoch 4</strong>: Training Accuracy = 99.67%, Validation Accuracy = 99.75%</li>
  <li><strong>Epoch 5</strong>: Training Accuracy = 99.73%, Validation Accuracy = 99.85%</li>
  <li><strong>Epoch 6</strong>: Training Accuracy = 99.76%, Validation Accuracy = 99.84%</li>
  <li><strong>Epoch 7</strong>: Training Accuracy = 99.78%, Validation Accuracy = 99.83%</li>
  <li><strong>Epoch 8</strong>: Training Accuracy = 99.79%, Validation Accuracy = 99.84%</li>
  <li><strong>Epoch 9</strong>: Training Accuracy = 99.69%, Validation Accuracy = 99.89%</li>
  <li><strong>Epoch 10</strong>: Training Accuracy = 99.77%, Validation Accuracy = 99.81%</li>
</ul>

<h3>Key Observations</h3>
<ul>
  <li>The model achieved <strong>high accuracy</strong> (above 99%) on both the training and validation sets, indicating excellent learning and generalization capabilities.</li>
  <li>The <strong>test accuracy</strong> of <strong>99.86%</strong> demonstrates that the model performs well on unseen data, confirming its robustness.</li>
  <li>The <strong>training and validation losses</strong> consistently decreased over epochs, indicating stable and effective training.</li>
</ul>

<h3>Final Metrics</h3>
<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Train Loss</strong></td>
      <td>0.0089</td>
    </tr>
    <tr>
      <td><strong>Train Acc</strong></td>
      <td>99.77%</td>
    </tr>
    <tr>
      <td><strong>Val Loss</strong></td>
      <td>0.0063</td>
    </tr>
    <tr>
      <td><strong>Val Acc</strong></td>
      <td>99.81%</td>
    </tr>
    <tr>
      <td><strong>Test Loss</strong></td>
      <td>0.0038</td>
    </tr>
    <tr>
      <td><strong>Test Acc</strong></td>
      <td>99.86%</td>
    </tr>
  </tbody>
</table>

<div class="section">
    <h2>Conclusion</h2>
    <p>
        DenseNet is a powerful deep learning architecture that leverages dense connectivity to improve feature reuse, gradient flow, and parameter efficiency. Its ability to achieve high accuracy with fewer parameters makes it a popular choice for image classification tasks. The implementation provided uses DenseNet121, which is trained on a custom dataset and evaluated for performance. This model can be further fine-tuned or adapted for specific applications, making it a versatile tool in the field of computer vision.
    </p>
</div>
<div class="section">
  <h2>Code Repository</h2>
  <p>
      The complete code for this project is available on <a href="https://github.com/miladbadeleh/Concrete-Crack-Detection-Using-DenseNet121" target="_blank">GitHub</a>. Feel free to explore, fork, and contribute!
  </p>
</div>

</body>
</html>
      <a href="../index.html#research" class="btn btn-primary">Back to Research</a>
    </div>
  </section>

 <!-- Footer -->
 <footer>
    <div class="container">
      <p>&copy; 2025 Milad Badeleh. All rights reserved.</p>
      <div class="social-links">
        <!-- <a href="#"><i class="fab fa-linkedin"></i></a> -->
        <!-- <a href="https://www.researchgate.net/profile/Milad-Badeleh"><i class="fab fa-researchgate"></i></a> -->
        <a href="https://github.com/miladbadeleh"><i class="fab fa-github"></i></a>
        <!-- <a href="https://orcid.org/your-orcid-id" target="_blank"><i class="fab fa-orcid"></i></a>
        <a href="https://www.scopus.com/authid/detail.uri?authorId=YOUR_SCOPUS_ID" target="_blank"><i class="fas fa-book"></i></a>
      <a href="https://scholar.google.com/citations?user=YOUR_GOOGLE_SCHOLAR_ID" target="_blank"><i class="fas fa-graduation-cap"></i></a> -->
      </div>
    </div>
  </footer>

  <script src="script.js"></script>
</body>
</html>